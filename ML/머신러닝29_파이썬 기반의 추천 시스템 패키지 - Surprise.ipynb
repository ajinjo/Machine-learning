{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da002e8",
   "metadata": {},
   "source": [
    "## 파이썬 기반의 추천 시스템 패키지 : Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise 패키지  \n",
    "\n",
    "컨텐츠 기반, 아이템 기반 협업 필터링, 잠재 요인 기반 협업 필터링  \n",
    "- 코드 최적화나 수행 속도 측면에서 좀 더 보완 필요\n",
    "\n",
    "추천 시스템은 상업적으로 가치가 크기 때문에 별도의 패키지로 제공되면 활용도가 매우 높을 것임  \n",
    "파이썬 기반의 추천 시스템 구축을 위한 전용 패키지 : Surprise    \n",
    "- 복잡한 알고리즘을 직접 구현하지 않고도 쉽고 간결한 API를 이용해\n",
    "- 파이썬 기반에서 추천 시스템을 구축할 수 있게 해줌\n",
    "- 파이썬 기반에서 사이킷런과 유사한 API와 프레임워크 제공\n",
    "- 추천 시스템의 전반적인 알고리즘을 이해하고 사이킷런 사용 경험이 있으면 쉽게 사용 가능\n",
    "- 사이킷런은 추천 전용 모듈 제공하지 않음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise 패키지 주요 장점\n",
    "- 다양한 추천 알고리즘(사용자 또는 아이템 기반 최근접 이웃 협업 필터링, SVD, SVD++, NMF 기반의 잠재 요인 협업 필터링 등)을 쉽게 적용해서 추천 시스템 구축 가능\n",
    "- Surprise의 핵심 API는 사이킷런의 핵심 API와 유사한 API 명으로 작성\n",
    "- fit(), predict() API로 추천 데이터 학습과 예측\n",
    "- train_test_split() : 추천 학습 데이터 세트와 예측 데이터 세트 분리\n",
    "- cross_validate(), GridSearchCV 클래스 : 추천 시스템을 위한 모델 셀렉션, 평가, 하이퍼 파라미터 튜닝 등 기능 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76057682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치 (Anaconda base에서)\n",
    "# conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296b665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "# 버전 확인\n",
    "import surprise \n",
    "\n",
    "print(surprise.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187834fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise 데이터 세트\n",
    "- 데이터 로드 : Dataset 클래스를 이용해서만 가능\n",
    "- 무비렌즈(MovieLens) 사이트에서 제공하는 과거 버전의 데이터 세트를 가져오는 API 제공\n",
    "-  Dataset.load_builtin('ml-100k') \n",
    "    - 무비렌즈 사이트에서 제공하는 과거 버전 데이터 세트인 'ml-100k'(10만 개 평점 데이터) \n",
    "    - 또는 'ml-1m'(100만 개 평점 데이터) 데이터를 아카이브 사이트로부터 내려받아 \n",
    "    - 로컬 디렉터리에 저장한 뒤 데이터 로드\n",
    "- 로드된 데이터 세트를 Surprise 패키지의 train_test_split() API를 이용해\n",
    "- 학습 데이터와 테스트 데이터 세트로 분리해서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28352910",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise에서 사용자-아이템 평점 데이터 적용 시 주의점!\n",
    "- 무비렌즈 사이트에서 다운받은 데이터 파일과 동일하게\n",
    "- 로우 레벨의 사용자-아이템 평점 데이터를 그대로 적용해야 함\n",
    "- (아이템 아이디를 칼럼명으로 변환한 형태로 변환하지 않음)\n",
    "- Surprise 자체적으로 로우 레벨의 데이터를 칼럼 레벨의 데이터로 변경하므로\n",
    "- 원본인 로우 레벨의 사용자-아이템 평점 데이터를 데이터 세트로 적용해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7fc8f",
   "metadata": {},
   "source": [
    "### Surprise 를 이용한 추천 시스템 구축 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "- 데이터 로드 방법 3가지\n",
    "\n",
    "1. 내장 데이터 사용  \n",
    "(1) 내장 데이터 로드  \n",
    "(2) 학습 데이터/테스트 데이터 세트로 분리  \n",
    "(3) 추천 행렬 분해 알고리즘으로 SVD 객체 생성  \n",
    "(4) 학습 수행  \n",
    "(5) 평점 예측 (모든 데이터에 대한 예측 / 특정 사용자, 아이템에 대한 예측)  \n",
    "(6) RMSE 평가(추천 예측 평점과 실제 평점과의 차이)\n",
    "\n",
    "2. csv 파일로 사용자 평점 데이터 생성  \n",
    "(1) 앞에서 사용한 ratings.csv 파일 읽어서 index/header 제거 후 새로운 파일로 저장한 후  \n",
    "(2) Reader 클래스 / Dataset.load_from_file()로 포맷에 맞게 파일로 부터 데이터 로드  \n",
    "(2) 학습 데이터/테스트 데이터 세트로 분리  \n",
    "(3) 추천 행렬 분해 알고리즘으로 SVD 객체 생성  \n",
    "(4) 학습 수행  \n",
    "(5) 평점 예측 (모든 데이터에 대한 예측 / 특정 사용자, 아이템에 대한 예측)  \n",
    "(6) RMSE 평가(추천 예측 평점과 실제 평점과의 차이) (결과 동일)\n",
    "\n",
    "3. 판다스 DataFrame기반\n",
    "- csv 파일로 사용자 평점 데이터 생성과 동일하게 수행\n",
    "- Reader 클래스 / Dataset.load_from_df()로 포맷에 맞게 데이터 로드  \n",
    "\n",
    "\n",
    "Dataset API 차이\n",
    "- Dataset.load_builtin()\n",
    "- Dataset.load_from_file() / Reader로 파일 포맷 지정\n",
    "- Dataset.load_from_df() / Reader로 파일 포맷 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15b7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset \n",
    "from surprise import accuracy \n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD : 행렬 분해 알고리즘(추천 알고리즘)  \n",
    "# Dataset : 원본 데이터 셋을 surprise에 적합한 포맷으로 만들어주는 데이터 셋  \n",
    "# accuracy : accuracy 모듈의 RMSE 함수 사용해서 평가  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478db4c6",
   "metadata": {},
   "source": [
    "### 1. 내장 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1d360a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내장 데이터를 로드하고 학습과 테스트 데이터로 분리\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k') \n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0) \n",
    "\n",
    "# 처음 load_builtin('ml-100k') 적용할 경우 로컬 디렉터리에 데이터가 없기 때문에\n",
    "# Dataset ml-100k could not be found. Do you want to download it? [Y/n] 출력\n",
    "# Y 입력\n",
    "# 저장 위치 : C:\\Users\\사용자이름/.surprise_data/ml-100k 열고 확인\n",
    "# u.data 파일 열고 확인 \n",
    "# - surprise에서 사용하는 'ml-100k' 데이터 세트는 과거 버전의 데이터 세트이고\n",
    "# 탭 문자로 구분되어 있고, 헤더 없음\n",
    "# userId, movieId, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072f616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise.trainset.Trainset"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ce451",
   "metadata": {},
   "source": [
    "### 추천 행렬 분해 알고리즘으로 SVD객체를 생성하고 학습수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73667de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x270c48aa460>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD() # 객체 생성\n",
    "algo.fit(trainset)  # 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa03f84",
   "metadata": {},
   "source": [
    "### 테스트 데이터 세트에 예상 평점 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test()메소드 호출 시 Prediction 객체의 리스트로 평점 예측 데이터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise에서 추천을 예측하는 메소드 2개    \n",
    "- test() : 사용자-아이템 평점 데이터 세트 전체에 대해서 추천 예측\n",
    "    - 즉, 입력된 데이터 세트에 대해 추천 데이터 세트 생성  \n",
    "- predict() : 개별 사용자와 영화에 대해 추천 평점 반환  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09724dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type : <class 'list'>  size: 25000\n",
      "prediction 결과의 최초 5개 추출\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='120', iid='282', r_ui=4.0, est=3.5749797403419725, details={'was_impossible': False}),\n",
       " Prediction(uid='882', iid='291', r_ui=4.0, est=3.9857843954218657, details={'was_impossible': False}),\n",
       " Prediction(uid='535', iid='507', r_ui=5.0, est=3.6730907060446762, details={'was_impossible': False}),\n",
       " Prediction(uid='697', iid='244', r_ui=5.0, est=3.4664110562079906, details={'was_impossible': False}),\n",
       " Prediction(uid='751', iid='385', r_ui=4.0, est=3.288137409073253, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 데이터에 대한 예측 : test() 사용\n",
    "predictions = algo.test(testset) # test() : 사이킷런의 predict()에 해당\n",
    "\n",
    "# 반환된 객체의 타입 확인 : 리스트 (25,000개 원소)\n",
    "print('prediction type :',type(predictions), ' size:',len(predictions))\n",
    "print('prediction 결과의 최초 5개 추출')\n",
    "predictions[:5]\n",
    "\n",
    "# 결과 \n",
    "# test() 메서드 호출 결과 : 파이썬 리스트\n",
    "# 입력 인자 데이터 세트의 크기와 같은 25,000 개\n",
    "# 25,000개의 Prediction 객체를 내부에 포함\n",
    "\n",
    "# Prediction  객체는 Surprise 패키지의 데이터 타입\n",
    "# 개별 사용자 아이디(uid), 영화(또는 아이템) 아이디(iid), \n",
    "# 실제 평점(r_ui)에 기반한 추천 예측 평점(est) 데이터를\n",
    "# 튜플 형태로 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30014f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '282', 3.5749797403419725),\n",
       " ('882', '291', 3.9857843954218657),\n",
       " ('535', '507', 3.6730907060446762)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  실제 평점 제외하고 예측 평점만 추출 (3개만)\n",
    "[ (pred.uid, pred.iid, pred.est) for pred in predictions[:3] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "609c6488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = None   est = 4.31   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# predict()메소드는 개별 사용자,아이템에 대한 예측 평점 정보를 반환\n",
    "\n",
    "# 사용자 아이디, 아이템 아이디는 문자열로 입력해야 함. \n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid)\n",
    "print(pred)\n",
    "\n",
    "# r_ui = None : 아직 평점 매기지 않았고\n",
    "# 예측 평점은 est = 3.87 \n",
    "\n",
    "# was_impossible : 예측값을 생성할 수 없는 데이터\n",
    "# 여기서는 모두 False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2d0e6",
   "metadata": {},
   "source": [
    "### 반환된 Prediction의 리스트 객체를 기반으로 RMSE 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6d6873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9511568474578436"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c038b93",
   "metadata": {},
   "source": [
    "### 2. csv 파일로 사용자 평점 데이터 생성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.csv와 movies.csv 사용  \n",
    "\n",
    "Surprise에서 OS 파일 로드 시 주의!  \n",
    "- 헤더 없어야 함 : 헤더 제거하고 새로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe4342b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 읽어서 인덱스와 헤더 제거하고 새로 저장\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "# ratings_noh.csv 파일로 unload 시 index 와 header를 모두 제거한 새로운 파일 생성.  \n",
    "ratings.to_csv('./data/ratings_noh.csv', index=False, header=False)\n",
    "\n",
    "# 저장된 파일 열어서 확인 (메모장으로 열어서 쉼표 확인)\n",
    "# timestamp는 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8812dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reader클래스로 파일의 포맷팅 지정하고 Dataset의 load_from_file()을 이용하여 데이터셋 로딩\n",
    "- Surprise  데이터 세트는 기본적으로 무비렌즈 데이터 형식을 따르므로  \n",
    "- 무비렌즈 데이터 형식이 아닌 다른 OS 파일의 경우    \n",
    "- Reader 클래스를 먼저 설정해야 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f2648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x270ca305820>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load_from_file() 읽어 오기 전에\n",
    "# Reader 클래스를 이용해 데이터 파일의 파싱 포맷 지정해야 함\n",
    "# 로딩될 csv 파일의 파싱 정보를 알려주기 위함\n",
    "# 칼럼 헤더 없고, 4개의 칼럼이 콤마로 분리되어 있음\n",
    "# 4개의 칼럼을 로딩 시 알려줘야 함\n",
    "\n",
    "from surprise import Reader\n",
    "\n",
    "# 칼렴명, 구분자(,), 평점 단위(0.5), 최대 평점(5)\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "data=Dataset.load_from_file('./data/ratings_noh.csv',reader=reader)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7548629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습과 테스트 데이터 세트로 분할하고 \n",
    "# SVD로 학습후 \n",
    "# 테스트데이터 평점 예측 후 \n",
    "# RMSE평가\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# 잠재 요인 크기 K 값을 나타내는 파라미터인 n_factors를 50으로 설정\n",
    "# 수행시마다 동일한 결과 도출을 위해 random_state 설정 \n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "\n",
    "# 학습 데이터 세트로 학습 후 테스트 데이터 세트로 평점 예측 후 RMSE 평가\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# 결과 동일\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d21ee",
   "metadata": {},
   "source": [
    "### 3. 판다스 DataFrame기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17a85018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv 파일 읽어서\n",
    "# load_from_df() 사용 / Reader 클래스로 설정\n",
    "\n",
    "import pandas as pd\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "ratings = pd.read_csv('./data/ratings.csv') \n",
    "reader = Reader(rating_scale=(0.5, 5.0)) \n",
    "\n",
    "# ratings DataFrame 에서 컬럼은 사용자 아이디, 아이템 아이디, 평점 순서를 지켜야 함\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# 잠재 요인 크기 K 값을 나타내는 파라미터인 n_factors를 50으로 설정\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# 결과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19fbce6",
   "metadata": {},
   "source": [
    "### Surprise 추천 알고리즘 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise 추천 알고리즘 클래스\n",
    "- SVD : 행렬 분해를 통한 잠재 요인 협업 필터링을 위한 SVD 알고리즘\n",
    "- KNNBasic : 최근접 이웃 협업 필터링을 위한 KNN 알고리즘\n",
    "- BaselineOnly : 사용자 Bias와 아이템 Bias를 감안한 SGD 베이스라인 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c84240",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias : 편향  \n",
    "    \n",
    "베이스라인 평점 (Baseline Rating)\n",
    "- 사람에 따라 평가 기준이 다름\n",
    "- 엄격하게 평가\n",
    "- 내용은 별로지만 좋게 평가\n",
    "- 전반적으로 후하게 평가\n",
    "- 냉정한 평가\n",
    "- 이러한 개인의 성향을 반영해서 \n",
    "- 아이템 평가에 편향성(bisas) 요소를 반영하여 평점을 부과하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7cae38",
   "metadata": {},
   "source": [
    "추천 알고리즘의 예측 성능 벤치마크 결과  \n",
    "http://surpriselib.com/  \n",
    "Core i5 7th gen (2.5 GHz), 8G RAM 사아에서 100k 데이터 세트로 테스트한 결과  \n",
    "\n",
    "\n",
    "- SVD++ : RMSE, MAE 성적이 가장 좋지만, 상대적으로 시간이 너무 올래 걸려\n",
    "    - 데이터가 조금만 더 커져도 사용하기 어려울 것으로 보임\n",
    "- SVD++을 제외하면 SVD와 k-NN Baseline이 가장 성능 평가 수치가 좋음\n",
    "- k-NN 자체는 성능이 상대적으로 뒤지지만, Baseline을 결합한 경우 성능 평가 수치가 대폭 향상됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "영화 평점을 베이스라인 평점을 고려해서 적용\n",
    "\n",
    "일반적인 베이스라인 평점 공식\n",
    "= 전체 평균 평점 + 사용자 편향 점수 + 아이템 편항 점수  \n",
    "\n",
    "전체 평균 평점  : 모든 사용자의 아이템에 대한 평점을 평균한 값  \n",
    "사용자 편향 점수 : 사용자별 아이템 평점 평균 값 - 전체 평균 평점  \n",
    "아이템 편항 점수 : 아이템별 평점 평균 값 - 전체 평균 평점\n",
    "    \n",
    "    \n",
    "예 : \n",
    "- 모든 사용자의 평균적인 영화 평점 : 3.5 (전체 평균 평점:3.5)\n",
    "- '어벤저스 3편'을 모든 사용자가 평균적으로 평점 4.2로 평가했다면\n",
    "- 영화 평가를 깐깐하게 하는 사용자 A가 '어벤저스 3편'을 어떻게 평가할 것인지 예상\n",
    "\n",
    "- 사용자 A의 어벤저스 3편의 베이스 라인 평점 = 3.5 - 0.5 + 0.7 = 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886375bb",
   "metadata": {},
   "source": [
    "### 교차 검증(Cross Validation)과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise는 교차 검증과 하이퍼 파라미터 튜닝을 위해\n",
    "- 사이킷런과 유사한 cross_validate()과 GridSearchCV 클래스 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate()를 이용한 교차 검증 예제\n",
    "\n",
    "- cross_validate() 이용해서\n",
    "- ratings.csv를 DataFrame으로 로드한 후\n",
    "- 데이터를 5개의 학습/검증 폴드 데이터 세트로 분리해 교차 검증 수행하고\n",
    "- RMSE, MAE로 성능 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9650b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8760  0.8690  0.8792  0.8724  0.8727  0.8739  0.0035  \n",
      "MAE (testset)     0.6728  0.6671  0.6755  0.6729  0.6695  0.6715  0.0029  \n",
      "Fit time          5.07    4.96    5.04    5.07    5.10    5.05    0.05    \n",
      "Test time         0.23    0.14    0.14    0.24    0.14    0.18    0.05    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87600669, 0.86901604, 0.87923373, 0.87240662, 0.87273449]),\n",
       " 'test_mae': array([0.6727602 , 0.6670597 , 0.67545422, 0.67285075, 0.6694697 ]),\n",
       " 'fit_time': (5.071372747421265,\n",
       "  4.961367845535278,\n",
       "  5.042373895645142,\n",
       "  5.066375017166138,\n",
       "  5.1003758907318115),\n",
       " 'test_time': (0.23001742362976074,\n",
       "  0.13901019096374512,\n",
       "  0.1350090503692627,\n",
       "  0.2400188446044922,\n",
       "  0.14001059532165527)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate \n",
    "\n",
    "# Pandas DataFrame에서 Surprise Dataset으로 데이터 로딩 \n",
    "ratings = pd.read_csv('./data/ratings.csv') \n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "algo = SVD(random_state=0) # K는 디폴트 100 적용\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True) \n",
    "\n",
    "# cross_validate() 결과\n",
    "# - 폴드별 성능 평가 수치와 전체 폴드의 평균 성능 평가 수치 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV 이용\n",
    "\n",
    "Surprise의  GridSearchCV도 사이킷런의  GridSearchCV와 유사하게 \n",
    "교차 검증을 통한 하이퍼 파라미터 최적화 수행\n",
    "\n",
    "SVD의 튜닝 파라미터\n",
    "- n_epochs : 반복 횟수 지정\n",
    "- n_factors : SVD 잠재 요인 K 크기 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c267140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876540262254331\n",
      "{'n_epochs': 20, 'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# 최적화할 파라미터들을 딕셔너리 형태로 지정. \n",
    "# bias는 기본 True 사용\n",
    "param_grid = {'n_epochs': [20, 40, 60], 'n_factors': [50, 100, 200] }\n",
    "\n",
    "# CV를 3개 폴드 세트로 지정, 성능 평가는 rmse, mse 로 수행 하도록 GridSearchCV 구성\n",
    "# 주의! : SVD 클래스 그대로 입력 (객체 algo로 입력하면 오류)\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# 최고 RMSE Evaluation 점수와 그때의 하이퍼 파라미터\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# 결과\n",
    "# 'n_epochs': 20, 'n_factors': 50일 때 3개 폴드의 검증 데이터 세트에서\n",
    "# 최적 RMSE가 0.877로 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d887c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8619bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e49cb9",
   "metadata": {},
   "source": [
    "### Surprise 를 이용한 개인화 영화 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "- 데이터 세트 전체를 학습 데이터 세트로 사용\n",
    "- SVD 이용해서 학습 수행\n",
    "- 특정 사용자가 평점을 매기지 않은 영화 추출한 후\n",
    "- 예측 평점 순으로 영화 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc3873",
   "metadata": {},
   "source": [
    "### SVD 학습은 TrainSet 클래스를 이용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfa79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Surprise를 이용해 잠재 요인 협업 필터링 기반의 개인화된 영화 추천 구현\n",
    "\n",
    "지금까지 예제는  \n",
    "- 학습 데이터로 fit() 학습한 뒤\n",
    "- 데스트 데이터로 test() 해서 예측 평점 계산하고\n",
    "- MSE/RMSE로 성능 평가\n",
    "\n",
    "이제 Surprise 패키지로 학습된 추천 알고리즘 기반으로\n",
    "특정 사용자가 아직 평점을 매기지 않은(관람하지 않은) 영화 중에서\n",
    "개인 취향에 가장 적절한 영화 추천\n",
    "\n",
    "ratings.csv 데이터를 학습 데이터와 테스트 데이터로 분리하지 않고  \n",
    "전체를 학습 데이터로 사용  \n",
    "그런데 Surprise는 데이터 세트를 train_test_split()을 이용해서   \n",
    "내부에서 사용하는 TrainSet 클래스 객체로 변환하지 않으면  \n",
    "fit()을 통해 학습할 수 없음 (오류 발생)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "312dd544",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetAutoFolds' object has no attribute 'global_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-45556a1b1857>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'movieId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 오류\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetAutoFolds' object has no attribute 'global_mean'"
     ]
    }
   ],
   "source": [
    "# train_test_split( )으로 분리되지 않는 Dataset에 \n",
    "# fit( )을 호출하면 오류 발생\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(data) # 오류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783a2ac",
   "metadata": {},
   "source": [
    "### DatasetAutoFolds를 이용한 전체 데이터를 TrainSet클래스 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터 세트 전체를 학습 데이터로 사용하려면  \n",
    "DatasetAutoFolds 클래스 이용  \n",
    "DatasetAutoFolds 객체를 생성한 뒤에  \n",
    "build_full_trainset() 메서드 호출  \n",
    "--> 전체 데이터를 학습 데이터 세트로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "007f6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터를 학습데이터로 생성\n",
    "\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "# DatasetAutoFolds 클래스를 ratings_noh.csv 파일 기반으로 생성. \n",
    "data_folds = DatasetAutoFolds(ratings_file='./data/ratings_noh.csv', reader=reader)\n",
    "\n",
    "#전체 데이터를 학습데이터로 생성함. \n",
    "trainset = data_folds.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de26fa",
   "metadata": {},
   "source": [
    "### SVD로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3087940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x270cc714700>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD 이용 학습 수행\n",
    "algo = SVD(n_epochs=20, n_factors=50, random_state=0)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "특정 사용자에 영화 추천\n",
    "- 특정 사용자 : userId = 9 \n",
    "- 아직 보지 않은 영화 목록 확인\n",
    "- 아직 평점을 매기지 않은 영화 선정한 뒤\n",
    "- 예측 평점 계산\n",
    "- 영화 상세 정보가 있는 movies.csv 파일 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebc20982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 아이디 9는 영화 아이디 42의 평점 없음\n",
      "    movieId                   title              genres\n",
      "38       42  Dead Presidents (1995)  Action|Crime|Drama\n"
     ]
    }
   ],
   "source": [
    "# userId=9가 movieId=42 봤는지 확인하고 (ratings.csv)\n",
    "# movieId=42 영화 정보 출력 (movies.csv)\n",
    "\n",
    "# 영화에 대한 상세 속성 정보 DataFrame로딩\n",
    "movies = pd.read_csv('./data/movies.csv')\n",
    "\n",
    "# userId=9 의 movieId 데이터 추출하여 movieId=42 데이터가 있는지 확인. \n",
    "movieIds = ratings[ratings['userId']==9]['movieId']\n",
    "if movieIds[movieIds==42].count() == 0:\n",
    "    print('사용자 아이디 9는 영화 아이디 42의 평점 없음')\n",
    "\n",
    "print(movies[movies['movieId']==42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d8410f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 9          item: 42         r_ui = None   est = 3.13   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# movieId=42 영화에 대해 userID=9 사용자의 추천 예상 평점 측정\n",
    "# - predict() 이용\n",
    "# - 주의 : 문자열 값\n",
    "\n",
    "uid = str(9)\n",
    "iid = str(42)\n",
    "\n",
    "pred = algo.predict(uid, iid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb6bef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n"
     ]
    }
   ],
   "source": [
    "# 사용자가 평점을 매기지 않은 전체 영화를 추출한 뒤에\n",
    "# 예측 평점순으로 영화 추천\n",
    "\n",
    "# 특정 아이디의 사용자가 아직 평점을 매기지 않은 영화 정보 반환하는 함수 생성\n",
    "def get_unseen_surprise(ratings, movies, userId):\n",
    "    #입력값으로 들어온 userId에 해당하는 사용자가 평점을 매긴 모든 영화를 리스트로 생성\n",
    "    seen_movies = ratings[ratings['userId']== userId]['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화들의 movieId를 리스트로 생성. \n",
    "    total_movies = movies['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화들의 movieId중 이미 평점을 매긴 영화의 movieId를 제외하여 리스트로 생성\n",
    "    unseen_movies= [movie for movie in total_movies if movie not in seen_movies]\n",
    "    print('평점 매긴 영화수:',len(seen_movies), '추천대상 영화수:',len(unseen_movies), \\\n",
    "          '전체 영화수:',len(total_movies))\n",
    "    \n",
    "    return unseen_movies\n",
    "\n",
    "# 아이디 9인 사용자가 아직 평점을 매기지 않은 영화 정보\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66f00d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 학습된 추천 알고리즘 클래스인 SVD 이용해\n",
    "# 높은 예측 평점을 가진 순으로 영화 추천하는 함수 \n",
    "# 영화 아이디, 영화 제목, 예측 평점 정보 반환\n",
    "\n",
    "def recomm_movie_by_surprise(algo, userId, unseen_movies, top_n=10):\n",
    "    # predict() 메소드 : 개별 사용자,아이템에 대한 예측 평점 정보를 반환\n",
    "    # 평점이 없는 영화에 predict() 메서드를 반복 수행 후 결과를 list 객체로 저장\n",
    "    predictions = [algo.predict(str(userId), str(movieId)) for movieId in unseen_movies]\n",
    "    \n",
    "    # predictions list 객체는 surprise의 Predictions 객체를 원소로 가지고 있음.\n",
    "    # [Prediction(uid='9', iid='1', est=3.69), Prediction(uid='9', iid='2', est=2.98),,,,]\n",
    "    # 예측 평점 est 값으로 정렬하기 위한 sortkey_est 함수 정의\n",
    "    # sortkey_est 함수는 list 객체의 sort() 함수의 키 값으로 사용되어 정렬 수행.\n",
    "    def sortkey_est(pred):\n",
    "        return pred.est  # 예측 평점 반환\n",
    "    \n",
    "    # sort() : 오름차순 정렬\n",
    "    # sort(reverse=True) : 내림차순 정렬\n",
    "    # sortkey_est( ) 함수 호출하고 예측 평점 반환받아\n",
    "    # 내림 차순으로 정렬 수행하고 top_n개의 최상위 값 추출.\n",
    "    predictions.sort(key=sortkey_est, reverse=True)\n",
    "    top_predictions= predictions[:top_n]\n",
    "    \n",
    "    # top_n으로 추출된 영화의 정보 추출. 영화 아이디, 추천 예상 평점, 제목 추출\n",
    "    top_movie_ids = [ int(pred.iid) for pred in top_predictions]\n",
    "    top_movie_rating = [ pred.est for pred in top_predictions]\n",
    "    top_movie_titles = movies[movies.movieId.isin(top_movie_ids)]['title']\n",
    "    top_movie_preds = [ (id, title, rating) for id, title, rating in zip(top_movie_ids, top_movie_titles, top_movie_rating)]\n",
    "    \n",
    "    return top_movie_preds\n",
    "\n",
    "# 결과 \n",
    "# 9번 아이디 사용자에게 \n",
    "# '유주얼 서스펙트', '대부', '좋은 친구들', '양들의 침묵', 'Pulp Fiction' 같은 스릴러/범죄 영화 및\n",
    "# '스타워즈' 같은 액션 영화 주로 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7e3413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n",
      "##### Top-10 추천 영화 리스트 #####\n",
      "Usual Suspects, The (1995) : 4.306302135700814\n",
      "Star Wars: Episode IV - A New Hope (1977) : 4.281663842987387\n",
      "Pulp Fiction (1994) : 4.278152632122759\n",
      "Silence of the Lambs, The (1991) : 4.226073566460876\n",
      "Godfather, The (1972) : 4.1918097904381995\n",
      "Streetcar Named Desire, A (1951) : 4.154746591122658\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) : 4.122016128534504\n",
      "Star Wars: Episode VI - Return of the Jedi (1983) : 4.108009609093436\n",
      "Goodfellas (1990) : 4.083464936588478\n",
      "Glory (1989) : 4.07887165526957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 9번 아이디 사용자가 아직 평점을 매기지 않은 영화 추출해서\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)\n",
    "# 높은 예측 평점 순으로 10개 영화 추천 리스트 생성\n",
    "top_movie_preds = recomm_movie_by_surprise(algo, 9, unseen_movies, top_n=10)\n",
    "\n",
    "print('##### Top-10 추천 영화 리스트 #####')\n",
    "\n",
    "# 리스트에서 영화 제목과 예측 평점 출력\n",
    "for top_movie in top_movie_preds:\n",
    "    print(top_movie[1], \":\", top_movie[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d3993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
